# SPDX-License-Identifier: MIT
# yaml-language-server: $schema=https://stack.lol/schemas/stack.config.schema.yaml
# This is a https://stack.lol stack metadata file.
slug: litellm
name: LiteLLM
icon: ğŸ¤–
flavor: DockerCompose
version: "1.56.4"
updated_at: 2024-12-29
description: Proxy Server to call 100+ LLMs in the OpenAI format
author: Berrie AI, Inc
license: MIT
homepage: https://www.litellm.ai
repository: https://github.com/BerriAI/litellm
stars: 21200
tags:
  - ai
  - llm
alternativeTo: [chatgpt, claude, perplexity]
readme: |
  Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]

  ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

  <hr>

  ### Features

  - Translate inputs to provider's `completion`, `embedding`, and `image_generation` endpoints
  - [Consistent output](https://docs.litellm.ai/docs/completion/output), text responses will always be available at `['choices'][0]['message']['content']`
  - Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
  - Set Budgets & Rate limits per project, api key, model [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)
i18n:
  es:
    description: Servidor proxy para llamar a mÃ¡s de 100 LLMs en el formato OpenAI
    readme: |-
      Llama a todas las APIs de LLM usando el formato OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### CaracterÃ­sticas

      - Traduce entradas a los endpoints de `completion`, `embedding` y `image_generation` del proveedor
      - [Salida consistente](https://docs.litellm.ai/docs/completion/output), las respuestas de texto siempre estarÃ¡n disponibles en `['choices'][0]['message']['content']`
      - LÃ³gica de reintento/respaldo en mÃºltiples implementaciones (por ejemplo, Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - Establecer presupuestos y lÃ­mites de tasa por proyecto, clave api, modelo [Servidor Proxy LiteLLM (Gateway LLM)](https://docs.litellm.ai/docs/simple_proxy)
  fr:
    description: Serveur Proxy pour appeler plus de 100 LLMs au format OpenAI
    readme: |-
      Appelez toutes les API LLM en utilisant le format OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### FonctionnalitÃ©s

      - Traduisez les entrÃ©es vers les endpoints `completion`, `embedding` et `image_generation` du fournisseur
      - [Sortie cohÃ©rente](https://docs.litellm.ai/docs/completion/output), les rÃ©ponses textuelles seront toujours disponibles Ã  `['choices'][0]['message']['content']`
      - Logique de rÃ©essai/repli sur plusieurs dÃ©ploiements (par ex. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - DÃ©finissez des budgets et des limites de taux par projet, clÃ© API, modÃ¨le [Serveur Proxy LiteLLM (Passerelle LLM)](https://docs.litellm.ai/docs/simple_proxy)
  de:
    description: Proxy-Server zum Aufruf von 100+ LLMs im OpenAI-Format
    readme: |-
      Rufen Sie alle LLM APIs im OpenAI-Format auf [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### Funktionen

      - Ãœbersetzt Eingaben in die `completion`, `embedding` und `image_generation` Endpunkte des Anbieters
      - [Konsistente Ausgabe](https://docs.litellm.ai/docs/completion/output), Textantworten sind immer unter `['choices'][0]['message']['content']` verfÃ¼gbar
      - Wiederholungs-/Fallback-Logik Ã¼ber mehrere Deployments (z.B. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - Festlegen von Budgets & Ratelimits pro Projekt, API-SchlÃ¼ssel, Modell [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)
  it:
    description: Server Proxy per chiamare piÃ¹ di 100 LLM nel formato OpenAI
    readme: |-
      Chiama tutte le API LLM usando il formato OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq ecc.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### Caratteristiche

      - Traduce gli input negli endpoint `completion`, `embedding` e `image_generation` del provider
      - [Output consistente](https://docs.litellm.ai/docs/completion/output), le risposte testuali saranno sempre disponibili in `['choices'][0]['message']['content']`
      - Logica di retry/fallback tra piÃ¹ deployment (es. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - Imposta budget e limiti di velocitÃ  per progetto, chiave api, modello [Server Proxy LiteLLM (Gateway LLM)](https://docs.litellm.ai/docs/simple_proxy)
  pt:
    description: Servidor Proxy para chamar 100+ LLMs no formato OpenAI
    readme: |-
      Chame todas as APIs de LLM usando o formato OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### Funcionalidades

      - Traduz entradas para endpoints de `completion`, `embedding` e `image_generation` do provedor
      - [SaÃ­da consistente](https://docs.litellm.ai/docs/completion/output), respostas de texto estarÃ£o sempre disponÃ­veis em `['choices'][0]['message']['content']`
      - LÃ³gica de tentativa/fallback em vÃ¡rias implantaÃ§Ãµes (ex: Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - Define OrÃ§amentos & Limites de taxa por projeto, chave de api, modelo [Servidor Proxy LiteLLM (Gateway LLM)](https://docs.litellm.ai/docs/simple_proxy)
  ru:
    description: ĞŸÑ€Ğ¾ĞºÑĞ¸-ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ±Ğ¾Ğ»ĞµĞµ 100 LLM Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI
    readme: |-
      Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ²ÑĞµ LLM API, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq Ğ¸ Ğ´Ñ€.]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸

      - ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ° `completion`, `embedding` Ğ¸ `image_generation`
      - [Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´](https://docs.litellm.ai/docs/completion/output), Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ±ÑƒĞ´ÑƒÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ğ¿Ğ¾ Ğ¿ÑƒÑ‚Ğ¸ `['choices'][0]['message']['content']`
      - Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº/Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Azure/OpenAI) - [ĞœĞ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€](https://docs.litellm.ai/docs/routing)
      - Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ±ÑĞ´Ğ¶ĞµÑ‚Ğ¾Ğ² Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°, API-ĞºĞ»ÑÑ‡Ğ°, Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ [ĞŸÑ€Ğ¾ĞºÑĞ¸-ÑĞµÑ€Ğ²ĞµÑ€ LiteLLM (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)
  ar:
    description: Ø®Ø§Ø¯Ù… ÙˆÙƒÙŠÙ„ Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† 100 Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ ÙƒØ¨ÙŠØ± Ø¨ØªÙ†Ø³ÙŠÙ‚ OpenAI
    readme: |-
      Ø§Ø³ØªØ¯Ø¹Ù Ø¬Ù…ÙŠØ¹ ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª LLM Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†Ø³ÙŠÙ‚ OpenAI [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq ÙˆØºÙŠØ±Ù‡Ø§]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª

      - ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `completion` Ùˆ`embedding` Ùˆ`image_generation` Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø²ÙˆØ¯
      - [Ù…Ø®Ø±Ø¬Ø§Øª Ù…ØªÙ†Ø§Ø³Ù‚Ø©](https://docs.litellm.ai/docs/completion/output)ØŒ Ø³ØªÙƒÙˆÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ù…ØªØ§Ø­Ø© Ø¯Ø§Ø¦Ù…Ù‹Ø§ ÙÙŠ `['choices'][0]['message']['content']`
      - Ù…Ù†Ø·Ù‚ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©/Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¹Ø¨Ø± Ø¹Ù…Ù„ÙŠØ§Øª Ù†Ø´Ø± Ù…ØªØ¹Ø¯Ø¯Ø© (Ù…Ø«Ù„ Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)
      - ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ§Øª ÙˆØ­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ù„ÙƒÙ„ Ù…Ø´Ø±ÙˆØ¹ ÙˆÙ…ÙØªØ§Ø­ API ÙˆÙ†Ù…ÙˆØ°Ø¬ [Ø®Ø§Ø¯Ù… LiteLLM Proxy (Ø¨ÙˆØ§Ø¨Ø© LLM)](https://docs.litellm.ai/docs/simple_proxy)
  zh:
    description: ä»£ç†æœåŠ¡å™¨ç”¨äºä»¥OpenAIæ ¼å¼è°ƒç”¨100å¤šä¸ªLLMæ¨¡å‹
    readme: |-
      ä½¿ç”¨OpenAIæ ¼å¼è°ƒç”¨æ‰€æœ‰LLM API [Bedrockã€Huggingfaceã€VertexAIã€TogetherAIã€Azureã€OpenAIã€Groqç­‰]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### åŠŸèƒ½ç‰¹ç‚¹

      - å°†è¾“å…¥è½¬æ¢åˆ°æä¾›å•†çš„`completion`ã€`embedding`å’Œ`image_generation`ç«¯ç‚¹
      - [ä¸€è‡´çš„è¾“å‡º](https://docs.litellm.ai/docs/completion/output)ï¼Œæ–‡æœ¬å“åº”å°†å§‹ç»ˆä½äº`['choices'][0]['message']['content']`
      - è·¨å¤šä¸ªéƒ¨ç½²ï¼ˆå¦‚Azure/OpenAIï¼‰çš„é‡è¯•/æ•…éšœè½¬ç§»é€»è¾‘ - [è·¯ç”±å™¨](https://docs.litellm.ai/docs/routing)
      - ä¸ºæ¯ä¸ªé¡¹ç›®ã€APIå¯†é’¥ã€æ¨¡å‹è®¾ç½®é¢„ç®—å’Œé€Ÿç‡é™åˆ¶ [LiteLLMä»£ç†æœåŠ¡å™¨ï¼ˆLLMç½‘å…³ï¼‰](https://docs.litellm.ai/docs/simple_proxy)
  hi:
    description: 100+ à¤¬à¤¡à¤¼à¥€ à¤­à¤¾à¤·à¤¾ à¤®à¥‰à¤¡à¤² à¤•à¥‹ OpenAI à¤«à¥‰à¤°à¥à¤®à¥ˆà¤Ÿ à¤®à¥‡à¤‚ à¤•à¥‰à¤² à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥à¤°à¥‰à¤•à¥à¤¸à¥€ à¤¸à¤°à¥à¤µà¤°
    readme: |-
      à¤¸à¤­à¥€ LLM APIs à¤•à¥‹ OpenAI à¤«à¥‰à¤°à¥à¤®à¥‡à¤Ÿ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤•à¥‡ à¤•à¥‰à¤² à¤•à¤°à¥‡à¤‚ [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq à¤†à¤¦à¤¿]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### à¤µà¤¿à¤¶à¥‡à¤·à¤¤à¤¾à¤à¤‚

      - à¤ªà¥à¤°à¤¦à¤¾à¤¤à¤¾ à¤•à¥‡ `completion`, `embedding`, à¤”à¤° `image_generation` à¤à¤‚à¤¡à¤ªà¥‰à¤‡à¤‚à¤Ÿà¥à¤¸ à¤•à¥‡ à¤²à¤¿à¤ à¤‡à¤¨à¤ªà¥à¤Ÿ à¤•à¤¾ à¤…à¤¨à¥à¤µà¤¾à¤¦ à¤•à¤°à¥‡à¤‚
      - [à¤¨à¤¿à¤°à¤‚à¤¤à¤° à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ](https://docs.litellm.ai/docs/completion/output), à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾à¤à¤‚ à¤¹à¤®à¥‡à¤¶à¤¾ `['choices'][0]['message']['content']` à¤ªà¤° à¤‰à¤ªà¤²à¤¬à¥à¤§ à¤¹à¥‹à¤‚à¤—à¥€
      - à¤•à¤ˆ à¤¡à¤¿à¤ªà¥à¤²à¥‰à¤¯à¤®à¥‡à¤‚à¤Ÿà¥à¤¸ (à¤œà¥ˆà¤¸à¥‡ Azure/OpenAI) à¤®à¥‡à¤‚ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸/à¤«à¥‰à¤²à¤¬à¥ˆà¤• à¤²à¥‰à¤œà¤¿à¤• - [à¤°à¤¾à¤‰à¤Ÿà¤°](https://docs.litellm.ai/docs/routing)
      - à¤ªà¥à¤°à¤¤à¤¿ à¤ªà¥à¤°à¥‹à¤œà¥‡à¤•à¥à¤Ÿ, à¤à¤ªà¥€à¤†à¤ˆ à¤•à¥à¤‚à¤œà¥€, à¤®à¥‰à¤¡à¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¬à¤œà¤Ÿ à¤”à¤° à¤¦à¤° à¤¸à¥€à¤®à¤¾à¤à¤‚ à¤¸à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚ [LiteLLM à¤ªà¥à¤°à¥‰à¤•à¥à¤¸à¥€ à¤¸à¤°à¥à¤µà¤° (LLM à¤—à¥‡à¤Ÿà¤µà¥‡)](https://docs.litellm.ai/docs/simple_proxy)
  ko:
    description: 100ê°œ ì´ìƒì˜ LLMì„ OpenAI í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡ì‹œ ì„œë²„
    readme: |-
      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### ê¸°ëŠ¥

      - ì œê³µìì˜ `completion`, `embedding`, `image_generation` ì—”ë“œí¬ì¸íŠ¸ë¡œ ì…ë ¥ì„ ë³€í™˜
      - [ì¼ê´€ëœ ì¶œë ¥](https://docs.litellm.ai/docs/completion/output), í…ìŠ¤íŠ¸ ì‘ë‹µì€ í•­ìƒ `['choices'][0]['message']['content']`ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
      - ì—¬ëŸ¬ ë°°í¬(ì˜ˆ: Azure/OpenAI)ì— ê±¸ì¹œ ì¬ì‹œë„/ëŒ€ì²´ ë¡œì§ - [ë¼ìš°í„°](https://docs.litellm.ai/docs/routing)
      - í”„ë¡œì íŠ¸, API í‚¤, ëª¨ë¸ë³„ ì˜ˆì‚° ë° ì†ë„ ì œí•œ ì„¤ì • [LiteLLM í”„ë¡ì‹œ ì„œë²„ (LLM ê²Œì´íŠ¸ì›¨ì´)](https://docs.litellm.ai/docs/simple_proxy)
  ja:
    description: 100ä»¥ä¸Šã®LLMã‚’OpenAIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‘¼ã³å‡ºã™ãŸã‚ã®ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼
    readme: |-
      ã™ã¹ã¦ã®LLM APIã‚’OpenAIãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‘¼ã³å‡ºã™ [Bedrockã€Huggingfaceã€VertexAIã€TogetherAIã€Azureã€OpenAIã€Groq ãªã©]

      ![preview](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)

      <hr>

      ### æ©Ÿèƒ½

      - ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®`completion`ã€`embedding`ã€`image_generation`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®å…¥åŠ›ã‚’å¤‰æ›
      - [ä¸€è²«ã—ãŸå‡ºåŠ›](https://docs.litellm.ai/docs/completion/output)ã€ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã¯å¸¸ã«`['choices'][0]['message']['content']`ã§åˆ©ç”¨å¯èƒ½
      - è¤‡æ•°ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆé–“ï¼ˆAzure/OpenAIãªã©ï¼‰ã§ã®å†è©¦è¡Œ/ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ - [Router](https://docs.litellm.ai/docs/routing)
      - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€APIã‚­ãƒ¼ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®äºˆç®—ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è¨­å®š [LiteLLM Proxyã‚µãƒ¼ãƒãƒ¼ï¼ˆLLMã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ï¼‰](https://docs.litellm.ai/docs/simple_proxy)
